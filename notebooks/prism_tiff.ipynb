{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle,Ellipse\n",
    "\n",
    "%matplotlib inline\n",
    "import dognet\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = \"DAPI,MAP2,vGlut,Bassoon,Cortactin,Gephyrin,Homer,NR2B,Phalloidin,PSD95,Shank3,Synapsin1,vGAT\".split(',')\n",
    "proteins = \"vGlut,Bassoon,Cortactin,Gephyrin,Homer,NR2B,Phalloidin,PSD95,Shank3,Synapsin1,vGAT\".split(',')\n",
    "req_channels=['Synapsin1', 'PSD95', 'vGlut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanx = pic.mean(axis=(1,2))\n",
    "minx = pic.min(axis=(1,2))\n",
    "maxx = pic.max(axis=(1,2))\n",
    "\n",
    "def get_normparams(data):\n",
    "    return data.mean(axis=(1,2)),data.min(axis=(1,2)),data.max(axis=(1,2))\n",
    "\n",
    "def normalize(im,norm_data):\n",
    "    meanx,minx,maxx = norm_data\n",
    "    x = np.copy(im.astype(np.float32))\n",
    "    x = x.transpose(1,2,0)\n",
    "    x = (x - meanx - minx)/(maxx - minx).astype(np.float32)\n",
    "    return x.transpose(2,0,1)\n",
    "\n",
    "def inference(net,image,get_intermediate=False):\n",
    "    x = np.expand_dims(image,0)\n",
    "    vx = Variable(torch.from_numpy(x).float()).cuda()\n",
    "    \n",
    "    res,inter = net(vx)\n",
    "    if get_intermediate:\n",
    "        return res.data.cpu().numpy(),inter.data.cpu().numpy()\n",
    "    return res.data.cpu().numpy()\n",
    "\n",
    "def draw_proccessed(x,image):\n",
    "    y = inference(net,normalize(x,get_normparams(rep21.data)))\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(20,10))\n",
    "   \n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    plt.imshow(image,cmap='gray',interpolation='bilinear')\n",
    "    return ax,y\n",
    "\n",
    "from skimage.draw import circle\n",
    "def make_labels(img,xs,ys,radius=5):\n",
    "    labels = np.zeros(img.shape[1:])\n",
    "    for xv,yv in zip(xs,ys):\n",
    "        rr,cc = circle(xv,yv,radius,labels.shape)\n",
    "        \n",
    "        labels[rr,cc]=1\n",
    "    return labels\n",
    "\n",
    "def estimate(net,test_set,s=2.):\n",
    "    mf1=[]\n",
    "    mprec =[]\n",
    "    mrec = []\n",
    "    mauc=[]\n",
    "             \n",
    "    for test in test_set:\n",
    "        y = inference(net,normalize(test.image,get_normparams(rep21.data)))\n",
    "        xx,yy,_ = dognet.find_peaks(y[0,0],3)\n",
    "        dog_pts = np.array([yy,xx]).transpose(1,0)\n",
    "        \n",
    "        #plt.imshow(test.image[0])\n",
    "        xs,ys = test.x,test.y\n",
    "        gt_pts = np.array([xs,ys]).transpose(1,0)\n",
    "        y_gt = make_labels(test.image,ys,xs,radius=1.5)\n",
    "       \n",
    "        fpr, tpr, thresholds = roc_curve(y_gt.flatten(),y[0,0].flatten())\n",
    "        mauc.append(auc(fpr, tpr))\n",
    "       \n",
    "        prec = 0\n",
    "        rec =0\n",
    "        f1 = 0 \n",
    "        if len(xx)>0:\n",
    "            prec,rec,f1,_ = dognet.get_metric(gt_pts,dog_pts,s=s)\n",
    "        mf1.append(f1)\n",
    "        mprec.append(prec)\n",
    "        mrec.append(rec)\n",
    "    return np.mean(mf1),np.mean(mprec),np.mean(mrec),np.mean(mauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DoGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = dognet.SimpleAnisotropic(3,11,2,learn_amplitude=False)\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load('Simple_Anisotropic_4_11_2_prism17.t7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_simple(data_image, x_list, y_list, window_size=5,func=np.median):\n",
    "    \"\"\"\n",
    "    Extract descriptors from an image using a giving point set\n",
    "    :param data_image: the image from which the descriptors will be extracted\n",
    "    :param x_list: list of synapse x coordinates  \n",
    "    :param y_list: list of synapse y coordinates\n",
    "    :param window_size: the size of window in which the descriptor is estimated\n",
    "    :return: array of descripors [x,y,amp,ax1_width,ax2_width,stdxy, angle_rad, y, x]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for x, y in zip(x_list, y_list):\n",
    "        x = int(round(x))\n",
    "        y = int(round(y))\n",
    "        patch = data_image[max(x - window_size, 0):x + window_size, max(y - window_size, 0):y + window_size]\n",
    "        result+= [func(patch)]\n",
    "    return np.array([result]).T,[\"{}_A\"]\n",
    "\n",
    "def extract_main(data_image, x_list, y_list, window_size=5):\n",
    "    dsc = np.array(dognet.extract_descriptor(data_image,x_list,y_list,window_size=window_size))\n",
    "    return dsc[:,[2,3,4,5]],[\"{}_A\",\"{}_stdx2\",\"{}_stdy2\",\"{}_stdxy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply DoGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hpc-4_Raid/vkulikov/MIT/r07c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r05c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r07c03f03.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r02c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r04c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r05c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r04c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r06c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r03c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r03c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r02c03f03.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r02c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r07c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r07c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r05c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r04c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r05c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r02c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r03c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r02c03f02.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r04c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r07c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r04c03f03.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r06c03f04.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r03c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r06c03f03.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r06c03f01.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r05c03f03.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r06c03f05.tif\n",
      "/media/hpc-4_Raid/vkulikov/MIT/r03c03f03.tif\n"
     ]
    }
   ],
   "source": [
    "#Pack as the network was trained\n",
    "import csv\n",
    "\n",
    "def process(path,func=extract_simple,draw=False):\n",
    "    raw = imread(path)\n",
    "    norm_raw = normalize(raw,get_normparams(raw))\n",
    "\n",
    "    data = np.concatenate([np.expand_dims(norm_raw[channels.index(s)],0) for s in req_channels])\n",
    "    y = inference(net,data)\n",
    "    xx,yy,_ = dognet.find_peaks(y[0,0],3)\n",
    "    pic= (data-data.min())/(data.max()-data.min()) \n",
    "    if draw:\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(pic.transpose(1,2,0))\n",
    "        plt.scatter(yy,xx,s=5,c='red')\n",
    "        \n",
    "    desc = []\n",
    "    #x,y,amp,ax1_width,ax2_width,stdxy, angle_rad, y, x\n",
    "    #2,3,4,5\n",
    "    #A,stdx2,stdy2,stdxy\n",
    "    fields = [\"X\",\"Y\"]\n",
    "    for pr in proteins:        \n",
    "        index = channels.index(pr)\n",
    "        dsc,base = func(raw[index],xx,yy)\n",
    "        desc+=[dsc]\n",
    "        fields+=[b.format(pr) for b in base]\n",
    "    results = np.concatenate([np.array([xx,yy]).T,np.concatenate(desc,1)],1)\n",
    "    \n",
    "   \n",
    "    ofile  = open(path[:-3]+\"csv\", \"wb\")\n",
    "    writer = csv.writer(ofile, delimiter=',', quotechar=' ', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    writer.writerow(fields)\n",
    "    writer.writerows(results.tolist())\n",
    "\n",
    "    ofile.close()\n",
    "    \n",
    "import os\n",
    "basepath = \"/media/hpc-4_Raid/vkulikov/MIT\"\n",
    "images = [os.path.join(basepath,f) for f in os.listdir(basepath) if f.endswith(\"tif\")]\n",
    "for im in images:\n",
    "    print(im)\n",
    "    process(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
